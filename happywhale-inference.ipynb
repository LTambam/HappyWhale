{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-04-14T13:06:17.505325Z","iopub.status.busy":"2022-04-14T13:06:17.505003Z","iopub.status.idle":"2022-04-14T13:07:21.635874Z","shell.execute_reply":"2022-04-14T13:07:21.635058Z","shell.execute_reply.started":"2022-04-14T13:06:17.50524Z"},"trusted":true},"outputs":[],"source":["!export CUDA_LAUNCH_BLOCKING=1 # for tracing issues\n","!pip install timm\n","!pip install torchinfo\n","!pip install --upgrade torchmetrics\n","\n","import numpy as np\n","import pandas as pd\n","import gc\n","import torch\n","import random\n","from typing import Callable\n","from typing import Dict\n","from typing import Optional\n","from PIL import Image\n","from PIL import ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True # fixes a weird issue\n","\n","from sklearn.preprocessing import LabelEncoder\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import torchmetrics\n","from torchinfo import summary\n","import pytorch_lightning as pl\n","\n","import timm\n","from timm.data.transforms_factory import create_transform\n","from timm.optim import create_optimizer_v2"]},{"cell_type":"markdown","metadata":{},"source":["# Configuration"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:08:34.867193Z","iopub.status.busy":"2022-04-14T13:08:34.866355Z","iopub.status.idle":"2022-04-14T13:08:34.875741Z","shell.execute_reply":"2022-04-14T13:08:34.872786Z","shell.execute_reply.started":"2022-04-14T13:08:34.867151Z"},"trusted":true},"outputs":[],"source":["class CFG:\n","    SEED = 42\n","    \n","    # Dataset\n","    N_FOLDS = 5\n","    NUM_WORKERS = 6 # number of threads for dataloaders\n","    \n","    ### Model\n","    MODEL_NAME = \"tf_efficientnet_b4\"\n","    PRETRAINED=True\n","    IMAGE_SIZE = 380\n","    EMBEDDING_SIZE = 512\n","    DROPOUT=0.0\n","    \n","    # Arcface\n","    S = 10\n","    M = 0.1\n","    \n","    # Training\n","    OPTIMIZER=\"adamW\"\n","    MODEL_PATH=\"model.ckpt\" # file to store the model checkpoints\n","    BATCH_SIZE = 32 # Effective batch size will be BATCH_SIZE*ACCUMULATE_GRAD_BATCHES\n","    ACCUMULATE_GRAD_BATCHES = 1 # \"1\" means updates model after every batch\n","    NUM_EPOCHS = 30\n","    LR = 0.001\n","    WEIGHT_DECAY = 0.000001\n","\n","    DEBUG = False # smaller set if debugging"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:08:37.541036Z","iopub.status.busy":"2022-04-14T13:08:37.540237Z","iopub.status.idle":"2022-04-14T13:08:37.551027Z","shell.execute_reply":"2022-04-14T13:08:37.550054Z","shell.execute_reply.started":"2022-04-14T13:08:37.54098Z"},"trusted":true},"outputs":[],"source":["# Make a deterministic pipeline\n","def fix_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    #gpu randomseed fixed\n","    torch.backends.cudnn.deterministic = True\n","    pl.seed_everything(seed)\n","\n","fix_seed(CFG.SEED)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:16:01.246129Z","iopub.status.busy":"2022-04-14T13:16:01.245391Z","iopub.status.idle":"2022-04-14T13:16:01.252731Z","shell.execute_reply":"2022-04-14T13:16:01.251139Z","shell.execute_reply.started":"2022-04-14T13:16:01.24609Z"},"trusted":true},"outputs":[],"source":["# Dataset PATHs\n","BASE_PATH = '../input/happywhale-enhanced-luke'\n","DATA_PATH = '../input/happy-whale-and-dolphin'\n","CHECKPOINTS_PATH = '../input/hwmodelcheckpoint/tf_efficientnet_b4_380.ckpt'\n","TRAIN_DIR = f\"{BASE_PATH}/train_images\"\n","TRAIN_DIR2 = f\"{BASE_PATH}/imgextra (1)\"\n","TEST_DIR = f\"{DATA_PATH}/test_images\"\n","TRAIN_CSV_PATH = '../input/hwmodelcheckpoint/train.csv'\n","TEST_CSV_PATH = '../input/hwmodelcheckpoint/test.csv'\n","\n","OUTPUT_DIR = '/kaggle/working'\n","TRAIN_CSV_OUTPUT_PATH = f\"{OUTPUT_DIR}/train.csv\"\n","TEST_CSV_OUTPUT_PATH = f\"{OUTPUT_DIR}/test.csv\"\n","ENCODER_CLASSES_PATH = f\"{OUTPUT_DIR}/encoder_classes.npy\"\n","CHECKPOINTS_DIR = f\"{OUTPUT_DIR}/checkpoints\"\n","SUBMISSION_CSV_PATH = f\"{OUTPUT_DIR}/submission.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:15:40.01764Z","iopub.status.busy":"2022-04-14T13:15:40.016761Z","iopub.status.idle":"2022-04-14T13:15:40.860301Z","shell.execute_reply":"2022-04-14T13:15:40.859458Z","shell.execute_reply.started":"2022-04-14T13:15:40.01759Z"},"trusted":true},"outputs":[],"source":["# get encoder classes\n","!cp ../input/hwmodelcheckpoint/encoder_classes.npy ./encoder_classes.npy \n","\n","# get train csv\n","!cp ../input/hwmodelcheckpoint/train.csv ./train.csv\n","\n","train_df = pd.read_csv(TRAIN_CSV_PATH)\n","\n","N_CLASSES = len(train_df[\"individual_id\"].unique())\n","\n","train_df.head()\n","\n","# get test csv\n","!cp ../input/hwmodelcheckpoint/test.csv ./test.csv\n","\n","test_df = pd.read_csv(TEST_CSV_PATH)\n","test_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:11:30.548219Z","iopub.status.busy":"2022-04-14T13:11:30.547519Z","iopub.status.idle":"2022-04-14T13:11:30.552401Z","shell.execute_reply":"2022-04-14T13:11:30.551654Z","shell.execute_reply.started":"2022-04-14T13:11:30.548183Z"},"trusted":true},"outputs":[],"source":["# need to convert to RGB because some images are grayscale\n","def pil_loader(path):\n","    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n","    with open(path, 'rb') as f:\n","        img = Image.open(f)\n","        return img.convert('RGB')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:11:33.47625Z","iopub.status.busy":"2022-04-14T13:11:33.475709Z","iopub.status.idle":"2022-04-14T13:11:33.485525Z","shell.execute_reply":"2022-04-14T13:11:33.483779Z","shell.execute_reply.started":"2022-04-14T13:11:33.47621Z"},"trusted":true},"outputs":[],"source":["class HappyWhaleDataset(Dataset):\n","    \"\"\"\n","    Class to Make any dataset\n","    \"\"\"\n","    def __init__(self, df: pd.DataFrame, transform: Optional[Callable] = None):\n","        self.df = df\n","        self.transform = transform\n","\n","        self.image_names = self.df[\"image\"].values\n","        self.image_paths = self.df[\"image_path\"].values\n","        self.targets = self.df[\"individual_id\"].values\n","\n","    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]:\n","        image_name = self.image_names[index]\n","\n","        image_path = self.image_paths[index]\n","\n","        image = pil_loader(image_path) # need this for testing\n","    \n","        if self.transform:\n","            image = self.transform(image)\n","\n","        target = self.targets[index]\n","        target = torch.tensor(target, dtype=torch.long)\n","\n","        return {\"image_name\": image_name, \"image\": image, \"target\": target}\n","\n","    def __len__(self) -> int:\n","        return len(self.df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:11:38.942938Z","iopub.status.busy":"2022-04-14T13:11:38.941973Z","iopub.status.idle":"2022-04-14T13:11:38.955709Z","shell.execute_reply":"2022-04-14T13:11:38.955011Z","shell.execute_reply.started":"2022-04-14T13:11:38.942863Z"},"trusted":true},"outputs":[],"source":["class LitDataModule(pl.LightningDataModule):\n","    \"\"\"\n","    Lightning data module for testing, validation, and testing\n","    \"\"\"\n","    def __init__(\n","        self,\n","        train_csv: str,\n","        test_csv: str,\n","        val_fold: float,\n","        image_size: int,\n","        batch_size: int,\n","        num_workers: int,\n","    ):\n","        super().__init__()\n","\n","        self.save_hyperparameters()\n","\n","        self.train_df = pd.read_csv(train_csv)\n","        self.test_df = pd.read_csv(test_csv)\n","        \n","        self.transform_train = create_transform( # should pre-fetch=True since we're using a DataLoader?\n","            input_size=(self.hparams.image_size, self.hparams.image_size),\n","            crop_pct=1.0,\n","        )\n","        self.transform_eval = create_transform(\n","            input_size=(self.hparams.image_size, self.hparams.image_size),\n","            crop_pct=1.0,\n","            is_training=False,\n","        )\n","        \n","    def setup(self, stage: Optional[str] = None):\n","        if stage == \"fit\" or stage is None:\n","            # Split train df using fold\n","            train_df = self.train_df[self.train_df.folds != self.hparams.val_fold].reset_index(drop=True)\n","            val_df = self.train_df[self.train_df.folds == self.hparams.val_fold].reset_index(drop=True)\n","\n","            self.train_dataset = HappyWhaleDataset(train_df, transform=self.transform_train)\n","            self.val_dataset = HappyWhaleDataset(val_df, transform=self.transform_eval)\n","\n","        if stage == \"test\" or stage is None:\n","            self.test_dataset = HappyWhaleDataset(self.test_df, transform=self.transform_eval)\n","\n","    def train_dataloader(self) -> DataLoader:\n","        return self._dataloader(self.train_dataset, train=True)\n","\n","    def val_dataloader(self) -> DataLoader:\n","        return self._dataloader(self.val_dataset)\n","\n","    def test_dataloader(self) -> DataLoader:\n","        return self._dataloader(self.test_dataset)\n","\n","    def _dataloader(self, dataset: HappyWhaleDataset, train: bool = False) -> DataLoader:\n","        if train == True:\n","            batch_size = self.hparams.batch_size\n","        else:\n","            batch_size = self.hparams.batch_size\n","\n","        return DataLoader(\n","            dataset,\n","            batch_size=batch_size,\n","            shuffle=train,\n","            num_workers=self.hparams.num_workers,\n","            pin_memory=True,\n","            drop_last=train,\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:11:51.387357Z","iopub.status.busy":"2022-04-14T13:11:51.386731Z","iopub.status.idle":"2022-04-14T13:11:51.395865Z","shell.execute_reply":"2022-04-14T13:11:51.395134Z","shell.execute_reply.started":"2022-04-14T13:11:51.387319Z"},"trusted":true},"outputs":[],"source":["class SoftMax(nn.Module):\n","    \"\"\"\n","    Softmax loss, just a linear layer\n","    \"\"\"\n","    def __init__(self, \n","        num_features: int,\n","        num_classes: int,\n","    ):\n","        super(SoftMax, self).__init__()\n","        \n","        self.num_features = num_features\n","        self.n_classes = num_classes\n","        self.W = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n","        nn.init.xavier_uniform_(self.W)\n","\n","    def forward(self, input: torch.Tensor, label: torch.Tensor, device: str = \"cuda\") -> torch.Tensor:\n","        x=input\n","        W=self.W\n","\n","        logits = F.linear(x, W)\n","\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:11:55.674079Z","iopub.status.busy":"2022-04-14T13:11:55.673545Z","iopub.status.idle":"2022-04-14T13:11:55.683171Z","shell.execute_reply":"2022-04-14T13:11:55.682497Z","shell.execute_reply.started":"2022-04-14T13:11:55.674039Z"},"trusted":true},"outputs":[],"source":["class ArcFace(nn.Module):\n","    \"\"\"\n","    ArcFace Loss\n","    \"\"\"\n","    def __init__(self, \n","        num_features: int,\n","        num_classes: int,\n","        s: float, \n","        m: float):\n","        super(ArcFace, self).__init__()\n","        \n","        self.num_features = num_features\n","        self.n_classes = num_classes\n","        self.s = s\n","        self.m = m\n","        self.W = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n","        nn.init.xavier_uniform_(self.W)\n","\n","    def forward(self, input: torch.Tensor, label: torch.Tensor, device: str = \"cuda\") -> torch.Tensor:\n","        # normalize features\n","        x = F.normalize(input)\n","        # normalize weights\n","        W = F.normalize(self.W)\n","        # dot product\n","        logits = F.linear(x, W)\n","\n","        if label is None:\n","            return logits\n","        \n","        # add margin\n","        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7)) # truncate it because we don't need that high resolution\n","        target_logits = torch.cos(theta + self.m)\n","\n","        # convert to one-hot encoding\n","        one_hot = torch.zeros_like(logits)\n","        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n","        output = logits * (1 - one_hot) + target_logits * one_hot\n","        \n","        # feature re-scale\n","        output *= self.s\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:11:59.648993Z","iopub.status.busy":"2022-04-14T13:11:59.648439Z","iopub.status.idle":"2022-04-14T13:11:59.672081Z","shell.execute_reply":"2022-04-14T13:11:59.669388Z","shell.execute_reply.started":"2022-04-14T13:11:59.648956Z"},"trusted":true},"outputs":[],"source":["class LitModule(pl.LightningModule):\n","    \"\"\"\n","    Lightning module\n","    \"\"\"\n","    def __init__(\n","        self,\n","        model_name: str,\n","        pretrained: bool,\n","        drop_rate: float,\n","        embedding_size: int,\n","        num_classes: int,\n","        arc_s: float,\n","        arc_m: float,\n","        optimizer: str,\n","        learning_rate: float,\n","        weight_decay: float,\n","        len_train_dl: int,\n","        epochs:int\n","    ):\n","        super().__init__()\n","\n","        self.save_hyperparameters()\n","\n","        self.model = timm.create_model(model_name, pretrained=pretrained, drop_rate=drop_rate)\n","        self.embedding = nn.Linear(self.model.get_classifier().in_features, embedding_size)\n","        self.model.reset_classifier(num_classes=0, global_pool=\"avg\")\n","\n","        self.arc = ArcFace(\n","            num_features=embedding_size,\n","            num_classes=num_classes,\n","            s=arc_s,\n","            m=arc_m,\n","        )\n","#         self.soft = SoftMax(\n","#             num_features=embedding_size,\n","#             num_classes=num_classes,\n","#         )\n","\n","        self.loss_fn = F.cross_entropy\n","        self.train_acc = torchmetrics.Accuracy()\n","        self.train_top_5_acc = torchmetrics.Accuracy(top_k=5)\n","        self.train_f1 = torchmetrics.F1Score(num_classes=num_classes)\n","        self.val_acc = torchmetrics.Accuracy()\n","        self.val_top_5_acc = torchmetrics.Accuracy(top_k=5)\n","        self.val_f1 = torchmetrics.F1Score(num_classes=num_classes)\n","\n","    def forward(self, images: torch.Tensor) -> torch.Tensor:\n","        features = self.model(images)\n","        embeddings = self.embedding(features)\n","\n","        return embeddings\n","\n","    def configure_optimizers(self):\n","        optimizer = create_optimizer_v2(\n","            self.parameters(),\n","            opt=self.hparams.optimizer,\n","            lr=self.hparams.learning_rate,\n","            weight_decay=self.hparams.weight_decay,\n","        )\n","        \n","        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","            optimizer,\n","            self.hparams.learning_rate,\n","            steps_per_epoch=self.hparams.len_train_dl,\n","            epochs=self.hparams.epochs,\n","        )\n","        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\"}\n","\n","        return [optimizer], [scheduler]\n","\n","    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n","        images, targets = batch[\"image\"], batch[\"target\"]\n","\n","        embeddings = self(images)\n","        outputs = self.arc(embeddings, targets, self.device)\n","\n","        loss = self.loss_fn(outputs, targets)\n","        self.train_acc(outputs, targets)\n","        self.train_top_5_acc(outputs, targets)\n","        self.train_f1(outputs, targets)\n","        \n","        self.log(f\"train_loss\", loss, batch_size=CFG.BATCH_SIZE)\n","        self.log(f\"train_acc\", self.train_acc, batch_size=CFG.BATCH_SIZE)\n","        self.log(f\"train_top_5_acc\", self.train_top_5_acc, batch_size=CFG.BATCH_SIZE)\n","        self.log(f\"train_f1\", self.train_f1,  batch_size=CFG.BATCH_SIZE)\n","        return loss\n","\n","    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n","        images, targets = batch[\"image\"], batch[\"target\"]\n","\n","        embeddings = self(images)\n","        outputs = self.arc(embeddings, targets, self.device)\n","\n","        loss = self.loss_fn(outputs, targets)\n","        self.val_acc(outputs, targets)\n","        self.val_top_5_acc(outputs, targets)\n","        self.val_f1(outputs, targets)\n","\n","        self.log(f\"val_loss\", loss, batch_size=CFG.BATCH_SIZE)\n","        self.log(f\"val_acc\", self.val_acc, batch_size=CFG.BATCH_SIZE)\n","        self.log(f\"val_top_5_acc\", self.val_top_5_acc, batch_size=CFG.BATCH_SIZE)\n","        self.log(f\"val_f1\", self.val_f1, batch_size=CFG.BATCH_SIZE)\n","\n","        return loss\n","    \n","    def predict_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n","        images = batch[\"image\"]\n","        \n","        embeddings = self(images) # when there's no labels, it just does SoftMax with normalization\n","        pred = self.arc(embeddings, label=None, device=self.device)\n","        \n","        predtop = torch.topk(pred, 5) # values and indices of top5 predictions\n","        \n","        return predtop"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T13:16:10.128539Z","iopub.status.busy":"2022-04-14T13:16:10.128255Z","iopub.status.idle":"2022-04-14T13:57:38.846975Z","shell.execute_reply":"2022-04-14T13:57:38.846141Z","shell.execute_reply.started":"2022-04-14T13:16:10.128505Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()\n","gc.collect()\n","\n","# load weights from checkpoint\n","module = LitModule.load_from_checkpoint(CHECKPOINTS_PATH)\n","\n","# create dataloaders\n","datamodule = LitDataModule(\n","    train_csv=str(TRAIN_CSV_OUTPUT_PATH),\n","    test_csv=str(TEST_CSV_OUTPUT_PATH),\n","    val_fold=2.0,\n","    image_size=CFG.IMAGE_SIZE,\n","    batch_size=CFG.BATCH_SIZE*2,\n","    num_workers=2,\n",")\n","datamodule.setup()\n","\n","test_dataloader = datamodule.test_dataloader()\n","\n","trainer = pl.Trainer(deterministic=True, gpus=1, max_epochs=1)\n","\n","# make raw predictions\n","predictions = trainer.predict(module, dataloaders=test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T14:38:58.009891Z","iopub.status.busy":"2022-04-14T14:38:58.009253Z","iopub.status.idle":"2022-04-14T14:38:58.017507Z","shell.execute_reply":"2022-04-14T14:38:58.016786Z","shell.execute_reply.started":"2022-04-14T14:38:58.009849Z"},"trusted":true},"outputs":[],"source":["# put predictions in a usable format\n","pred_vals = []\n","pred_inds = []\n","\n","for i in range(len(predictions)):\n","    pred_vals.append(predictions[i].values)\n","    pred_inds.append(predictions[i].indices)\n","\n","predictions_values = torch.cat((pred_vals), 0)\n","predictions_indices = torch.cat((pred_inds), 0)\n","\n","# convert to numpy and save em so we don't have to do this again\n","predictions_val_np = predictions_values.numpy()\n","predictions_ind_np = predictions_indices.numpy()\n","predictions_val_df = pd.DataFrame(predictions_val_np)\n","predictions_ind_df = pd.DataFrame(predictions_ind_np)\n","predictions_val_df.to_csv('prediction_values.csv')\n","predictions_ind_df.to_csv('prediction_indices.csv')\n","\n","# reload the saved encoder from classes in training\n","encoder = LabelEncoder()\n","encoder.classes_ = np.load(ENCODER_CLASSES_PATH, allow_pickle=True)\n","\n","# take inverse transform for each column and get individual IDs\n","predictions_ids_df = predictions_ind_df.copy()\n","for i in range(5):\n","    predictions_ids_df[i] = encoder.inverse_transform(predictions_ind_df[i])\n","\n","# save them\n","predictions_ids_df.to_csv('prediction_ids.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# predictions_val_df = pd.read_csv('../input/hwmodelcheckpoint/prediction_values.csv', index_col=None)\n","# predictions_ids_df = pd.read_csv('../input/hwmodelcheckpoint/prediction_ids.csv', index_col=None)\n","# predictions_val_df = predictions_val_df.drop(['Unnamed: 0'], axis=1)\n","# predictions_ids_df = predictions_ids_df.drop(['Unnamed: 0'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sub_df = pd.read_csv(\"../input/happy-whale-and-dolphin/sample_submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check score with just new individuals as first and shuffle. Result is 0.113 which means 11.3% of the data is new individuals\n","predictions_ids_dfnew = predictions_ids_df.copy()\n","predictions_ids_dfnew = predictions_ids_dfnew.sample(frac=1).reset_index(drop=True)\n","predictions_ids_dfnew.loc[:, '0'] = \"new_individual\"\n","pred_seriesnew = predictions_ids_dfnew.apply(lambda x: \" \".join(x), axis=1)\n","submission_dfnew = sub_df.copy()\n","submission_dfnew[\"predictions\"] = pred_seriesnew\n","submission_dfnew.to_csv(\"submissionnew.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-04-14T15:12:28.291498Z","iopub.status.busy":"2022-04-14T15:12:28.291217Z","iopub.status.idle":"2022-04-14T15:12:28.306736Z","shell.execute_reply":"2022-04-14T15:12:28.30608Z","shell.execute_reply.started":"2022-04-14T15:12:28.291449Z"},"trusted":true},"outputs":[],"source":["predictions_ids_df1 = predictions_ids_df.copy()\n","new_predictions_ids_df1 = predictions_ids_df.copy()\n","th = [0.1, 0.3, 0.5, 0.7] # 0.3 thresh gave best result, 0.284\n","\n","newid = False\n","\n","# this is a crappy way to go through and add \"new_individual\" if it was below a certain threshold but I was in a rush\n","for i, rows in enumerate(predictions_val_df.iterrows()):\n","    for j in range(5):\n","        if (not newid):\n","            if (rows[1][j] < (1-th[0])):\n","                newid = True\n","                new_predictions_ids_df1.loc[i, str(j)] = \"new_individual\"\n","                # shuffle the predictions in the row over if there is a new individual\n","                for k in range(4-j):\n","                    new_predictions_ids_df1.loc[i, str(k+1)] = predictions_ids_df1.loc[i, str(k)]\n","            \n","        else:\n","            newid = False\n","            break\n","\n","# put submission in the correct format and save top 3 thresh results are 0.284 at 0.3, 0.254 at 0.1 and 0.251 at 0.5\n","pred_series1 = new_predictions_ids_df1.apply(lambda x: \" \".join(x), axis=1)\n","submission_df1 = sub_df.copy()\n","submission_df1[\"predictions\"] = pred_series1\n","submission_df1.to_csv(\"submission01.csv\", index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
